{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOohfTiouH7cgxSatuGwPxB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palak1593/Audio_to_text/blob/main/Audio_To_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXjeynl30cnC",
        "outputId": "89520127-a56d-4376-f5fd-5ee82989ac62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition # allows you to recognize and transcribe speech from various audio sources, such as microphones or audio files,\n",
        "!pip install pydub # simplifies working with audio files.Perform various operations on audio, such as splitting, merging, adjusting volume,convert audio formats, applying effects, and more.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import os #provides a way to interact with the operating system,\n",
        "          #allowing you to perform various operations related to file management, directory manipulation, environment variables, and more.\n",
        "import subprocess\n",
        "from google.colab import files # used in Google Colab notebooks to interact with files and user input/output\n",
        "from pydub import AudioSegment  #imports the AudioSegment class from the PyDub library in Python.\n",
        "                               #can easily load, manipulate, and export audio files in your Python code.\n",
        "from pydub.silence import split_on_silence #imports the split_on_silence function from the pydub.silence module in the PyDub library.\n",
        "                                           #This function allows you to split an audio file into segments based on periods of silence.\n",
        ""
      ],
      "metadata": {
        "id": "HmXnn8HK1cV2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload audio file\n",
        "\n",
        "files.upload() #The files.upload() function allows you to upload files from your local machine to your Google Colab environment."
      ],
      "metadata": {
        "id": "CrP0IRC33bPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert mp3 to wav file\n",
        "subprocess.call(['ffmpeg', '-i', 'hello (1).mp3','wav_file.wav'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWqZvivT31UC",
        "outputId": "e58f141d-95fa-4b99-9d87-cf3df3ba6e0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the recognizer\n",
        "r = sr.Recognizer()       #Creates an instance of the Recognizer class from the speech_recognition module in Python.\n",
        "                          #The Recognizer class is the main component of the SpeechRecognition library and is used for speech recognition purposes.\n",
        "\n",
        "# a function that splits the audio file into chunks\n",
        "# and applies speech recognition\n",
        "\n",
        "def get_large_audio_transcription(path):\n",
        "    \"\"\"\n",
        "    Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\n",
        "    \"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_wav(path)\n",
        "\n",
        "   #The split_on_silence() function analyzes the input audio segment, identifies periods of silence based on the provided parameters,\n",
        "   #and returns a list of audio chunks. Each chunk represents a portion of the original audio segment, separated by periods of silence.\n",
        "    chunks = split_on_silence(sound,\n",
        "       # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "        min_silence_len = 700,  #specifies the minimum duration of silence in milliseconds that should be considered as a separation point for splitting\n",
        "\n",
        "        silence_thresh = sound.dBFS-14,  #determines the silence threshold level in decibels (dBFS) that defines what audio level is considered silence.\n",
        "                                         #The sound.dBFS-14 expression sets the threshold relative to the average audio level of the sound segment.\n",
        "\n",
        "        keep_silence=700, #This parameter determines the duration of silence to keep between the resulting audio chunks in milliseconds.\n",
        "                          #It allows you to add a specified duration of silence between the chunks.\n",
        "    )\n",
        "\n",
        "    folder_name = \"audio-chunks\"\n",
        "\n",
        "    # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name): #checks if a directory with the name specified by the folder_name variable exists.\n",
        "                                       #If the directory doesn't exist, it creates a new directory with that name using the os.mkdir() function.\n",
        "        os.mkdir(folder_name)\n",
        "\n",
        "    whole_text = \"\"\n",
        "\n",
        "    # process each chunk\n",
        "    for i, audio_chunk in enumerate(chunks, start=1): #The enumerate() function is used to retrieve each audio chunk along with its corresponding index.\n",
        "                                                       #The start=1 argument sets the starting index value as 1 instead of the default 0.\n",
        "\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\") # This line creates the filename for the current audio chunk.\n",
        "                                                                    #It uses the os.path.join() function to join the folder_name directory path with the filename, which is generated dynamically based on the index of the current chunk.\n",
        "\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\") #This exports the current audio chunk to a WAV file with the filename specified by chunk_filename.\n",
        "                                                         # The export() method of the AudioSegment class is used for exporting the chunk, and the format=\"wav\" argument specifies that the file should be saved in WAV format\n",
        "\n",
        "        \"\"\" each audio chunk obtained from the split_on_silence() function will be saved as a separate WAV file in the folder_name directory.\n",
        "        The files will be named as \"chunk1.wav\", \"chunk2.wav\", and so on, corresponding to their respective index in the chunks list.\"\"\"\n",
        "\n",
        "        # recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:  #Uses the AudioFile class from the speech_recognition module in Python.\n",
        "                                                      #It opens an audio file (chunk) using the AudioFile context manager and records the audio data for speech recognition\n",
        "\n",
        "            audio_listened = r.record(source)   # This line uses the record() method of the Recognizer class (r) to record the audio data from the opened source (audio file).\n",
        "                                              #The record() method reads the audio data from the source and stores it in the audio_listened variable.\n",
        "\n",
        "            # try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened) #recognize_google() method of the Recognizer class (r) to perform speech recognition on the variable 'audio_listened' which contains the recorded audio data.\n",
        "\n",
        "            except sr.UnknownValueError as e:  #If an UnknownValueError exception occurs during the speech recognition process (e.g., when no speech is detected or the speech cannot be recognized), the code inside this block is executed.\n",
        "                print(\"Error:\", str(e))\n",
        "\n",
        "            else:   # If no exception occurs during the try block, the code inside this block is executed.\n",
        "\n",
        "                text = f\"{text.capitalize()}. \"  #This line capitalizes the recognized text and appends a period and a space at the end.\n",
        "\n",
        "                print(chunk_filename, \":\", text)  #prints the filename of the chunk and the recognized text.\n",
        "\n",
        "                whole_text += text  #This line appends the recognized text to the whole_text variable, which is likely a cumulative variable to store the recognized text from multiple audio chunks.\n",
        "\n",
        "    # return the text for all chunks detected\n",
        "    return whole_text\n",
        ""
      ],
      "metadata": {
        "id": "mOzx2sGR5k7j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/wav_file.wav\"\n",
        "print(\"\\nFull text:\", get_large_audio_transcription(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJYdUY6J5rYn",
        "outputId": "ab6e6144-0984-4efb-e393-85519f900621"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio-chunks/chunk1.wav : Try and keep on trying. \n",
            "audio-chunks/chunk2.wav : The rule that must be followed underscore to become an expert in anything. \n",
            "\n",
            "Full text: Try and keep on trying. The rule that must be followed underscore to become an expert in anything. \n"
          ]
        }
      ]
    }
  ]
}